{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb19e071-71bd-4c58-a4ec-e6563a1a85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import struct\n",
    "import pandas as pd\n",
    "import threading\n",
    "import subprocess\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "\n",
    "hw_type = 'gpu'\n",
    "HOST_ROOT_DIR = '/raid/cuvs-bench-runner'\n",
    "DATASET_NAME = 'miracl-5M'\n",
    "ALGORITHM = 'cuvs_cagra'\n",
    "K = 10 # Top K to return during search\n",
    "query_batch_sizes = [1, 10, 100] # List of query batch sizes to evaluate\n",
    "\n",
    "# Compute ground truth. Only needs to be ran once. Note: only works with GPU image (bug?).\n",
    "compute_ground_truth = True\n",
    "\n",
    "# Run parameter optimization grid search\n",
    "run_parameter_sweep = False\n",
    "\n",
    "# Delete previous results in ./datasets/$DATASET_NAME/result/ \n",
    "# and /datasets/$DATASET_NAME/index folder\n",
    "clear_previous_results = True\n",
    "\n",
    "# Docker images for CPU and GPU runs\n",
    "CUVS_BENCH_CPU_DOCKER_IMG = 'rapidsai/cuvs-bench-cpu:25.10a-py3.12-amd64'\n",
    "CUVS_BENCH_GPU_DOCKER_IMG = 'rapidsai/cuvs-bench:25.10-cuda13.0-py3.12'\n",
    "\n",
    "SEARCH_MODE = 'latency' # Choose 'latency' or 'throughput'\n",
    "\n",
    "# TODO: restrict algorithms based on hw_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e82758-4716-4e00-b86f-7a835ec7d61f",
   "metadata": {},
   "source": [
    "# Compute Ground Truth for Vector Search Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b2a58a-3faa-41af-b647-de0e881278b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ground truth.... \n",
      "\n",
      "Reading whole dataset\n",
      "Dataset size    1.9 GB, shape (4999995, 384), dtype int8\n",
      "Reading queries from file /data/benchmarks/datasets/miracl-5M/query.i8bin\n",
      "Calculating true nearest neighbors\n",
      "Step 0/9:\n",
      "Step 1/9:\n",
      "Step 2/9:\n",
      "Step 3/9:\n",
      "Step 4/9:\n",
      "Step 5/9:\n",
      "Step 6/9:\n",
      "Step 7/9:\n",
      "Step 8/9:\n",
      "Step 9/9:\n",
      "writing /data/benchmarks/datasets/miracl-5M/groundtruth.neighbors.ibin (10005, 10) uint32 ...\n",
      "writing /data/benchmarks/datasets/miracl-5M/groundtruth.distances.fbin (10005, 10) float32 ...\n"
     ]
    }
   ],
   "source": [
    "def generate_docker_run_cmd(command, HOST_ROOT_DIR, hw_type):\n",
    "    \"\"\"\n",
    "    Docker run command wrapper.\n",
    "\n",
    "    hw_type: str\n",
    "      Select 'cpu' or 'gpu'.\n",
    "    \"\"\"\n",
    "    if hw_type == 'cpu':\n",
    "        docker_run_cmd = f\"\"\"docker run --rm \\\n",
    "          --user root \\\n",
    "          --shm-size=16GB \\\n",
    "          --entrypoint /bin/bash \\\n",
    "          --workdir /data/benchmarks \\\n",
    "          -v {HOST_ROOT_DIR}:/data/benchmarks \\\n",
    "          {CUVS_BENCH_CPU_DOCKER_IMG} -c \"{command}\"\n",
    "          \"\"\"\n",
    "    elif hw_type == 'gpu':\n",
    "        docker_run_cmd = f\"\"\"docker run --gpus all --rm \\\n",
    "          --user root \\\n",
    "          --shm-size=16GB \\\n",
    "          --entrypoint /bin/bash \\\n",
    "          --workdir /data/benchmarks \\\n",
    "          -v {HOST_ROOT_DIR}:/data/benchmarks \\\n",
    "          {CUVS_BENCH_GPU_DOCKER_IMG} -c \"{command}\"\n",
    "          \"\"\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown hardware value: {hw_type}. Select 'cpu' or 'gpu'.\")\n",
    "\n",
    "    return(docker_run_cmd)\n",
    "\n",
    "if compute_ground_truth:\n",
    "    print('Computing ground truth.... \\n')\n",
    "    \n",
    "    # Get file extension for base.* file in data directory\n",
    "    base_file = glob.glob(f'{HOST_ROOT_DIR}/datasets/{DATASET_NAME}/base.*')\n",
    "    PRECISION_SUFFIX = base_file[0].split('.')[-1]\n",
    "    \n",
    "    # Generate ground truth data\n",
    "    CONTAINER_DATASET_PATH = '/data/benchmarks/datasets'\n",
    "    CONTAINER_DATASET_PATH = CONTAINER_DATASET_PATH + '/' + DATASET_NAME\n",
    "    gen_ground_truth_cmd = f'''python -m cuvs_bench.generate_groundtruth \\\n",
    "        {CONTAINER_DATASET_PATH}/base.{PRECISION_SUFFIX} \\\n",
    "        --queries={CONTAINER_DATASET_PATH}/query.{PRECISION_SUFFIX} \\\n",
    "        --output {CONTAINER_DATASET_PATH} -k {K}\n",
    "        '''\n",
    "    \n",
    "    # Generate docker command for generating ground truth in cuvs-bench.\n",
    "    # Currently implementation ONLY works with GPU.\n",
    "    ground_truth_docker_cmd = generate_docker_run_cmd(gen_ground_truth_cmd, HOST_ROOT_DIR, 'gpu')\n",
    "    \n",
    "    # Run the command\n",
    "    subprocess.run(ground_truth_docker_cmd, shell=True)\n",
    "    \n",
    "elif compute_ground_truth==False:\n",
    "    print(f'Skipping ground truth computation since compute_ground_truth=False.')\n",
    "\n",
    "else:\n",
    "    raise ValueError(f'Unknown compute_ground_truth value. It must be a boolean.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b8e98-6ebb-4453-ab68-4950e4a381ce",
   "metadata": {},
   "source": [
    "# Run Parameter Optimization Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59eb7800-a373-4db9-b075-0e5823f70cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping parameter grid search since run_parameter_sweep=False. \n",
      "\n",
      "CPU times: user 3.13 ms, sys: 0 ns, total: 3.13 ms\n",
      "Wall time: 5.32 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/data/benchmarks/datasets/miracl-5M/result/': No such file or directory\n",
      "rm: cannot remove '/data/benchmarks/datasets/miracl-5M/index/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Root path scripts directory mounted to within docker container\n",
    "DOCKER_ROOT_PATH = '/data/benchmarks'\n",
    "\n",
    "if clear_previous_results:\n",
    "    subprocess.run(f'rm -r {DOCKER_ROOT_PATH}/datasets/{DATASET_NAME}/result/', shell=True)\n",
    "    subprocess.run(f'rm -r {DOCKER_ROOT_PATH}/datasets/{DATASET_NAME}/index/', shell=True)\n",
    "\n",
    "if run_parameter_sweep:\n",
    "    param_sweep_batch_size = 10000\n",
    "\n",
    "    cuvs_param_sweep_cmd = generate_cuvs_bench_run_cmd(DATASET_NAME, ALGORITHM, \n",
    "                                                        K, param_sweep_batch_size, 'base', \n",
    "                                                        SEARCH_MODE, SEARCH_ONLY=False)\n",
    "\n",
    "    param_sweep_docker_cmd = generate_docker_run_cmd(cuvs_param_sweep_cmd, HOST_ROOT_DIR, hw_type)\n",
    "    subprocess.run(param_sweep_docker_cmd, shell=True)\n",
    "    \n",
    "    # Plotting results\n",
    "    plotting_cmd = f'''python -m cuvs_bench.plot \\\n",
    "        --dataset {DATASET_NAME} \\\n",
    "        --mode latency \\\n",
    "        --output-filepath /data/benchmarks/datasets/{DATASET_NAME} \\\n",
    "        --dataset-path /data/benchmarks/datasets \\\n",
    "        --algorithms {ALGORITHM} \\\n",
    "        --search -bs {param_sweep_batch_size} -k {K}\n",
    "        '''\n",
    "    \n",
    "    plotting_docker_cmd = generate_docker_run_cmd(plotting_cmd, HOST_ROOT_DIR, hw_type)\n",
    "    \n",
    "    # Run the command\n",
    "    subprocess.run(plotting_docker_cmd, shell=True)\n",
    "    \n",
    "elif run_parameter_sweep == False:\n",
    "    print(f'Skipping parameter grid search since run_parameter_sweep=False. \\n')\n",
    "\n",
    "else:\n",
    "    raise ValueError(f'Unknown run_parameter_sweep value. It must be a boolean.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecaac10-af05-4557-9d49-24f2a1d9eac7",
   "metadata": {},
   "source": [
    "# Run Benchmark with Optimal Parameters\n",
    "Determine build/search parameters that are optimal based on the grid search performed. Update the 'goups.test' field in `./configs/ALGORITHM.yaml` for the specific algorithm desired. \n",
    "\n",
    "The following code will run a single index build and then multiple searches at different batch sizes to evaluate search performance. Outputs are provided as a csv file ending with `*merged.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d862f7be-0f7c-4e1b-a23f-dcf28b57b7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building search index with cuvs_cagra. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19T21:58:06+00:00\n",
      "Running /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH\n",
      "Run on (128 X 2395.52 MHz CPU s)\n",
      "CPU Caches:\n",
      "  L1 Data 32 KiB (x64)\n",
      "  L1 Instruction 32 KiB (x64)\n",
      "  L2 Unified 512 KiB (x64)\n",
      "  L3 Unified 16384 KiB (x32)\n",
      "Load Average: 3.17, 6.05, 8.07\n",
      "command_line: /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH --build --data_prefix=/data/benchmarks/datasets --benchmark_out_format=json --benchmark_counters_tabular=true --benchmark_out=/data/benchmarks/datasets/miracl-5M/result/build/cuvs_cagra,test.json.lock --force miracl-5M_cuvs_cagra,test,k10,bs1_d44fab54-c592-11f0-a33b-f2f9a06ebb36.json\n",
      "dataset: miracl-5M\n",
      "dim: 384\n",
      "distance: euclidean\n",
      "gpu_driver_version: 13.0\n",
      "gpu_gpuDirectRDMASupported: 1\n",
      "gpu_hostNativeAtomicSupported: 0\n",
      "gpu_mem_bus_width: 5120\n",
      "gpu_mem_freq: 1512000000.000000\n",
      "gpu_mem_global_size: 85094825984\n",
      "gpu_mem_shared_size: 167936\n",
      "gpu_name: NVIDIA A100 80GB PCIe\n",
      "gpu_pageableMemoryAccess: 0\n",
      "gpu_pageableMemoryAccessUsesHostPageTables: 0\n",
      "gpu_runtime_version: 13.0\n",
      "gpu_sm_count: 108\n",
      "gpu_sm_freq: 1410000000.000000\n",
      "host_cores_used: 64\n",
      "host_pagesize: 4096\n",
      "host_processors_sysconf: 128\n",
      "host_processors_used: 128\n",
      "host_total_ram_size: 1081743925248\n",
      "host_total_swap_size: 8589930496\n",
      "n_records: 4999995\n",
      "2025-11-19T21:59:06+00:00\n",
      "Running /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH\n",
      "Run on (128 X 2395.52 MHz CPU s)\n",
      "CPU Caches:\n",
      "  L1 Data 32 KiB (x64)\n",
      "  L1 Instruction 32 KiB (x64)\n",
      "  L2 Unified 512 KiB (x64)\n",
      "  L3 Unified 16384 KiB (x32)\n",
      "Load Average: 29.36, 12.91, 10.29\n",
      "command_line: /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH --search --data_prefix=/data/benchmarks/datasets --benchmark_counters_tabular=true --override_kv=k:10 --override_kv=n_queries:1 --benchmark_min_warmup_time=1 --benchmark_out_format=json --mode=latency --benchmark_out=/data/benchmarks/datasets/miracl-5M/result/search/cuvs_cagra,test,k10,bs1.json --force miracl-5M_cuvs_cagra,test,k10,bs1_d44fab54-c592-11f0-a33b-f2f9a06ebb36.json\n",
      "dataset: miracl-5M\n",
      "dim: 384\n",
      "distance: euclidean\n",
      "gpu_driver_version: 13.0\n",
      "gpu_gpuDirectRDMASupported: 1\n",
      "gpu_hostNativeAtomicSupported: 0\n",
      "gpu_mem_bus_width: 5120\n",
      "gpu_mem_freq: 1512000000.000000\n",
      "gpu_mem_global_size: 85094825984\n",
      "gpu_mem_shared_size: 167936\n",
      "gpu_name: NVIDIA A100 80GB PCIe\n",
      "gpu_pageableMemoryAccess: 0\n",
      "gpu_pageableMemoryAccessUsesHostPageTables: 0\n",
      "gpu_runtime_version: 13.0\n",
      "gpu_sm_count: 108\n",
      "gpu_sm_freq: 1410000000.000000\n",
      "host_cores_used: 64\n",
      "host_pagesize: 4096\n",
      "host_processors_sysconf: 128\n",
      "host_processors_used: 128\n",
      "host_total_ram_size: 1081743925248\n",
      "host_total_swap_size: 8589930496\n",
      "max_k: 10\n",
      "max_n_queries: 10005\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] [21:58:06.881022] Using the dataset file '/data/benchmarks/datasets/miracl-5M/base.i8bin'\n",
      "[I] [21:58:06.887192] Overwriting file: /data/benchmarks/datasets/miracl-5M/index/cuvs_cagra_test.graph_degree96.intermediate_graph_degree96.graph_build_algoNN_DESCENT\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Benchmark                                                                                                             Time             CPU   Iterations        GPU graph_degree index_size intermediate_graph_degree\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "cuvs_cagra_test.graph_degree96.intermediate_graph_degree96.graph_build_algoNN_DESCENT/process_time/real_time       54.0 s          2397 s             1    53.9667           96         5M                        96 graph_build_algo=\"NN_DESCENT\"\n",
      "[I] [21:59:06.127656] Using the query file '/data/benchmarks/datasets/miracl-5M/query.i8bin'\n",
      "[I] [21:59:06.127705] Using the ground truth file '/data/benchmarks/datasets/miracl-5M/groundtruth.neighbors.ibin'\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Benchmark                                                                                                             Time             CPU   Iterations        GPU    Latency     Recall end_to_end items_per_second      itopk          k  n_queries search_width total_queries\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "cuvs_cagra_test.graph_degree96.intermediate_graph_degree96.graph_build_algoNN_DESCENT/process_time/real_time      0.525 ms        0.525 ms         1339   515.028u   524.838u   0.951382   0.702759       1.90536k/s         64         10          1            1        1.339k\n",
      "-- Using cuVS bench found in conda environment.\n",
      "\n",
      "Indexing completed in 67.21 s. [Including docker init] \n",
      "\n",
      "Running vector search with cuvs_cagra. \n",
      "\n",
      "  Query batch size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19T21:59:15+00:00\n",
      "Running /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH\n",
      "Run on (128 X 2395.52 MHz CPU s)\n",
      "CPU Caches:\n",
      "  L1 Data 32 KiB (x64)\n",
      "  L1 Instruction 32 KiB (x64)\n",
      "  L2 Unified 512 KiB (x64)\n",
      "  L3 Unified 16384 KiB (x32)\n",
      "Load Average: 24.92, 12.50, 10.18\n",
      "command_line: /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH --search --data_prefix=/data/benchmarks/datasets --benchmark_counters_tabular=true --override_kv=k:10 --override_kv=n_queries:1 --benchmark_min_warmup_time=1 --benchmark_out_format=json --mode=latency --benchmark_out=/data/benchmarks/datasets/miracl-5M/result/search/cuvs_cagra,test,k10,bs1.json --force miracl-5M_cuvs_cagra,test,k10,bs1_fcfce1e8-c592-11f0-91c9-06fae178afbb.json\n",
      "dataset: miracl-5M\n",
      "dim: 384\n",
      "distance: euclidean\n",
      "gpu_driver_version: 13.0\n",
      "gpu_gpuDirectRDMASupported: 1\n",
      "gpu_hostNativeAtomicSupported: 0\n",
      "gpu_mem_bus_width: 5120\n",
      "gpu_mem_freq: 1512000000.000000\n",
      "gpu_mem_global_size: 85094825984\n",
      "gpu_mem_shared_size: 167936\n",
      "gpu_name: NVIDIA A100 80GB PCIe\n",
      "gpu_pageableMemoryAccess: 0\n",
      "gpu_pageableMemoryAccessUsesHostPageTables: 0\n",
      "gpu_runtime_version: 13.0\n",
      "gpu_sm_count: 108\n",
      "gpu_sm_freq: 1410000000.000000\n",
      "host_cores_used: 64\n",
      "host_pagesize: 4096\n",
      "host_processors_sysconf: 128\n",
      "host_processors_used: 128\n",
      "host_total_ram_size: 1081743925248\n",
      "host_total_swap_size: 8589930496\n",
      "max_k: 10\n",
      "max_n_queries: 10005\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] [21:59:15.137142] Using the query file '/data/benchmarks/datasets/miracl-5M/query.i8bin'\n",
      "[I] [21:59:15.137192] Using the ground truth file '/data/benchmarks/datasets/miracl-5M/groundtruth.neighbors.ibin'\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Benchmark                                                                                                             Time             CPU   Iterations        GPU    Latency     Recall end_to_end items_per_second      itopk          k  n_queries search_width total_queries\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "cuvs_cagra_test.graph_degree96.intermediate_graph_degree96.graph_build_algoNN_DESCENT/process_time/real_time      0.525 ms        0.525 ms         1339   515.423u   525.164u   0.951382   0.703194       1.90419k/s         64         10          1            1        1.339k\n",
      "-- Using cuVS bench found in conda environment.\n",
      "\n",
      "  Query batch size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19T21:59:24+00:00\n",
      "Running /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH\n",
      "Run on (128 X 2395.52 MHz CPU s)\n",
      "CPU Caches:\n",
      "  L1 Data 32 KiB (x64)\n",
      "  L1 Instruction 32 KiB (x64)\n",
      "  L2 Unified 512 KiB (x64)\n",
      "  L3 Unified 16384 KiB (x32)\n",
      "Load Average: 21.32, 12.14, 10.09\n",
      "command_line: /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH --search --data_prefix=/data/benchmarks/datasets --benchmark_counters_tabular=true --override_kv=k:10 --override_kv=n_queries:10 --benchmark_min_warmup_time=1 --benchmark_out_format=json --mode=latency --benchmark_out=/data/benchmarks/datasets/miracl-5M/result/search/cuvs_cagra,test,k10,bs10.json --force miracl-5M_cuvs_cagra,test,k10,bs10_0260037c-c593-11f0-ab72-da0b2695bcbf.json\n",
      "dataset: miracl-5M\n",
      "dim: 384\n",
      "distance: euclidean\n",
      "gpu_driver_version: 13.0\n",
      "gpu_gpuDirectRDMASupported: 1\n",
      "gpu_hostNativeAtomicSupported: 0\n",
      "gpu_mem_bus_width: 5120\n",
      "gpu_mem_freq: 1512000000.000000\n",
      "gpu_mem_global_size: 85094825984\n",
      "gpu_mem_shared_size: 167936\n",
      "gpu_name: NVIDIA A100 80GB PCIe\n",
      "gpu_pageableMemoryAccess: 0\n",
      "gpu_pageableMemoryAccessUsesHostPageTables: 0\n",
      "gpu_runtime_version: 13.0\n",
      "gpu_sm_count: 108\n",
      "gpu_sm_freq: 1410000000.000000\n",
      "host_cores_used: 64\n",
      "host_pagesize: 4096\n",
      "host_processors_sysconf: 128\n",
      "host_processors_used: 128\n",
      "host_total_ram_size: 1081743925248\n",
      "host_total_swap_size: 8589930496\n",
      "max_k: 10\n",
      "max_n_queries: 10005\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] [21:59:24.171969] Using the query file '/data/benchmarks/datasets/miracl-5M/query.i8bin'\n",
      "[I] [21:59:24.172017] Using the ground truth file '/data/benchmarks/datasets/miracl-5M/groundtruth.neighbors.ibin'\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Benchmark                                                                                                             Time             CPU   Iterations        GPU    Latency     Recall end_to_end items_per_second      itopk          k  n_queries search_width total_queries\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "cuvs_cagra_test.graph_degree96.intermediate_graph_degree96.graph_build_algoNN_DESCENT/process_time/real_time      0.543 ms        0.543 ms         1288   533.432u     543.2u    0.95502   0.699642       18.4095k/s         64         10         10            1        12.88k\n",
      "-- Using cuVS bench found in conda environment.\n",
      "\n",
      "  Query batch size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19T21:59:33+00:00\n",
      "Running /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH\n",
      "Run on (128 X 2395.52 MHz CPU s)\n",
      "CPU Caches:\n",
      "  L1 Data 32 KiB (x64)\n",
      "  L1 Instruction 32 KiB (x64)\n",
      "  L2 Unified 512 KiB (x64)\n",
      "  L3 Unified 16384 KiB (x32)\n",
      "Load Average: 18.19, 11.77, 9.99\n",
      "command_line: /opt/conda/bin/ann/CUVS_CAGRA_ANN_BENCH --search --data_prefix=/data/benchmarks/datasets --benchmark_counters_tabular=true --override_kv=k:10 --override_kv=n_queries:100 --benchmark_min_warmup_time=1 --benchmark_out_format=json --mode=latency --benchmark_out=/data/benchmarks/datasets/miracl-5M/result/search/cuvs_cagra,test,k10,bs100.json --force miracl-5M_cuvs_cagra,test,k10,bs100_07c2bf30-c593-11f0-9805-725331ad4b15.json\n",
      "dataset: miracl-5M\n",
      "dim: 384\n",
      "distance: euclidean\n",
      "gpu_driver_version: 13.0\n",
      "gpu_gpuDirectRDMASupported: 1\n",
      "gpu_hostNativeAtomicSupported: 0\n",
      "gpu_mem_bus_width: 5120\n",
      "gpu_mem_freq: 1512000000.000000\n",
      "gpu_mem_global_size: 85094825984\n",
      "gpu_mem_shared_size: 167936\n",
      "gpu_name: NVIDIA A100 80GB PCIe\n",
      "gpu_pageableMemoryAccess: 0\n",
      "gpu_pageableMemoryAccessUsesHostPageTables: 0\n",
      "gpu_runtime_version: 13.0\n",
      "gpu_sm_count: 108\n",
      "gpu_sm_freq: 1410000000.000000\n",
      "host_cores_used: 64\n",
      "host_pagesize: 4096\n",
      "host_processors_sysconf: 128\n",
      "host_processors_used: 128\n",
      "host_total_ram_size: 1081743925248\n",
      "host_total_swap_size: 8589930496\n",
      "max_k: 10\n",
      "max_n_queries: 10005\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] [21:59:33.204200] Using the query file '/data/benchmarks/datasets/miracl-5M/query.i8bin'\n",
      "[I] [21:59:33.204248] Using the ground truth file '/data/benchmarks/datasets/miracl-5M/groundtruth.neighbors.ibin'\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Benchmark                                                                                                             Time             CPU   Iterations        GPU    Latency     Recall end_to_end items_per_second      itopk          k  n_queries search_width total_queries\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "cuvs_cagra_test.graph_degree96.intermediate_graph_degree96.graph_build_algoNN_DESCENT/process_time/real_time      0.712 ms        0.712 ms          983   702.063u   712.005u    0.95467   0.699901       140.449k/s         64         10        100            1         98.3k\n",
      "-- Using cuVS bench found in conda environment.\n",
      "\n",
      "All search tasks have been completed.\n"
     ]
    }
   ],
   "source": [
    "# Run single index build command:\n",
    "print(f'Building search index with {ALGORITHM}. \\n')\n",
    "cuvs_bench_build_cmd = generate_cuvs_bench_run_cmd(DATASET_NAME, ALGORITHM, K, 1, 'test', SEARCH_MODE, SEARCH_ONLY=False)\n",
    "build_telem = run_command_with_telemetry(generate_docker_run_cmd(cuvs_bench_build_cmd, HOST_ROOT_DIR, hw_type), 'build', hw_type)\n",
    "build_telem_df = pd.Series(build_telem).to_frame().T\n",
    "\n",
    "# Build stage also does a single search afterwards. \n",
    "# --build flag errors out looking for search results.\n",
    "\n",
    "print(f'Indexing completed in {build_telem_df[\"build_duration_sec\"].values[0]:.2f} s. [Including docker init] \\n')\n",
    "\n",
    "# Run vector search at various batch sizes:\n",
    "print(f'Running vector search with {ALGORITHM}. \\n')\n",
    "search_telem_store = []\n",
    "for bs in query_batch_sizes:\n",
    "    print(f'  Query batch size: {bs}')\n",
    "    cuvs_bench_search_cmd = generate_cuvs_bench_run_cmd(DATASET_NAME, ALGORITHM, K, bs, 'test', SEARCH_MODE, SEARCH_ONLY=True)\n",
    "    search_telem = run_command_with_telemetry(generate_docker_run_cmd(cuvs_bench_search_cmd, HOST_ROOT_DIR, hw_type), 'search')\n",
    "    search_telem['query_batch_size'] = bs\n",
    "    search_telem_store.append(search_telem)\n",
    "\n",
    "print('All search tasks have been completed.')\n",
    "search_telem_df = pd.DataFrame(search_telem_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94469d11-108d-4d8e-8c0b-08c064f03108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_name</th>\n",
       "      <th>index_name</th>\n",
       "      <th>recall</th>\n",
       "      <th>throughput</th>\n",
       "      <th>latency</th>\n",
       "      <th>threads</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>GPU</th>\n",
       "      <th>end_to_end</th>\n",
       "      <th>itopk</th>\n",
       "      <th>...</th>\n",
       "      <th>build_max_cpu_util</th>\n",
       "      <th>build_max_ram_gb</th>\n",
       "      <th>build_avg_gpu_util</th>\n",
       "      <th>build_max_gpu_util</th>\n",
       "      <th>build_max_vram_gb</th>\n",
       "      <th>search_duration_sec</th>\n",
       "      <th>search_avg_cpu_util</th>\n",
       "      <th>search_max_cpu_util</th>\n",
       "      <th>search_max_ram_gb</th>\n",
       "      <th>query_batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cuvs_cagra_test</td>\n",
       "      <td>cuvs_cagra_test.graph_degree96.intermediate_gr...</td>\n",
       "      <td>0.955020</td>\n",
       "      <td>18409.491429</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543216</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.699642</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.6</td>\n",
       "      <td>24.644588</td>\n",
       "      <td>53.911765</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.326294</td>\n",
       "      <td>8.017712</td>\n",
       "      <td>2.044444</td>\n",
       "      <td>11.9</td>\n",
       "      <td>18.237324</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuvs_cagra_test</td>\n",
       "      <td>cuvs_cagra_test.graph_degree96.intermediate_gr...</td>\n",
       "      <td>0.951382</td>\n",
       "      <td>1904.189319</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525218</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.703194</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.6</td>\n",
       "      <td>24.644588</td>\n",
       "      <td>53.911765</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.326294</td>\n",
       "      <td>8.017409</td>\n",
       "      <td>2.044444</td>\n",
       "      <td>11.9</td>\n",
       "      <td>18.123444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cuvs_cagra_test</td>\n",
       "      <td>cuvs_cagra_test.graph_degree96.intermediate_gr...</td>\n",
       "      <td>0.954670</td>\n",
       "      <td>140448.937366</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.712112</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.699901</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.6</td>\n",
       "      <td>24.644588</td>\n",
       "      <td>53.911765</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.326294</td>\n",
       "      <td>8.019078</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>11.9</td>\n",
       "      <td>18.331116</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         algo_name                                         index_name  \\\n",
       "0  cuvs_cagra_test  cuvs_cagra_test.graph_degree96.intermediate_gr...   \n",
       "1  cuvs_cagra_test  cuvs_cagra_test.graph_degree96.intermediate_gr...   \n",
       "2  cuvs_cagra_test  cuvs_cagra_test.graph_degree96.intermediate_gr...   \n",
       "\n",
       "     recall     throughput   latency  threads  cpu_time       GPU  end_to_end  \\\n",
       "0  0.955020   18409.491429  0.000543        1  0.543216  0.000533    0.699642   \n",
       "1  0.951382    1904.189319  0.000525        1  0.525218  0.000515    0.703194   \n",
       "2  0.954670  140448.937366  0.000712        1  0.712112  0.000702    0.699901   \n",
       "\n",
       "   itopk  ...  build_max_cpu_util  build_max_ram_gb  build_avg_gpu_util  \\\n",
       "0   64.0  ...                97.6         24.644588           53.911765   \n",
       "1   64.0  ...                97.6         24.644588           53.911765   \n",
       "2   64.0  ...                97.6         24.644588           53.911765   \n",
       "\n",
       "   build_max_gpu_util  build_max_vram_gb  search_duration_sec  \\\n",
       "0               100.0          13.326294             8.017712   \n",
       "1               100.0          13.326294             8.017409   \n",
       "2               100.0          13.326294             8.019078   \n",
       "\n",
       "   search_avg_cpu_util  search_max_cpu_util  search_max_ram_gb  \\\n",
       "0             2.044444                 11.9          18.237324   \n",
       "1             2.044444                 11.9          18.123444   \n",
       "2             2.033333                 11.9          18.331116   \n",
       "\n",
       "   query_batch_size  \n",
       "0                10  \n",
       "1                 1  \n",
       "2               100  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load results from ./result/search dir and merge with telemetry\n",
    "latency_test_csv = glob.glob(f'{HOST_ROOT_DIR}/datasets/{DATASET_NAME}/result/search/{ALGORITHM},test,k{K},bs*,latency.csv')\n",
    "\n",
    "latency_test_results = pd.concat([pd.read_csv(fn) for fn in latency_test_csv])\n",
    "\n",
    "# Merge result dataframe with telemetry\n",
    "latency_test_results = pd.concat([latency_test_results, build_telem_df], axis=1)\n",
    "latency_test_results[['n_queries', 'k']] = latency_test_results[['n_queries', 'k']].astype(int)\n",
    "latency_test_results = latency_test_results.merge(search_telem_df, left_on='n_queries', right_on='query_batch_size')\n",
    "\n",
    "latency_test_results.to_csv(f'{HOST_ROOT_DIR}/datasets/{DATASET_NAME}/{ALGORITHM},test,k{K},latency,merged.csv', index=False)\n",
    "\n",
    "latency_test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
