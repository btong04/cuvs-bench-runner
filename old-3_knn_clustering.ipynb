{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb19e071-71bd-4c58-a4ec-e6563a1a85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import struct\n",
    "import pandas as pd\n",
    "import threading\n",
    "import subprocess\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from functools import wraps\n",
    "\n",
    "hw_type = 'gpu'\n",
    "DATASET_NAME = 'miracl-fp32-1024d-8M'\n",
    "n_per_cluster = 1000 # Number of vectors per cluster\n",
    "max_iter = 20 # Maximum number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f060fb8b-1dc7-4767-af0e-a34f6745dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(d, prefix):\n",
    "    \"\"\"\n",
    "    Add prefix to dictionary keys.\n",
    "    \"\"\"\n",
    "    return {f\"{prefix}{k}\": v for k, v in d.items()}\n",
    "    \n",
    "def monitor_resources(stop_event, log, hw_type, interval=0.25):\n",
    "    \"\"\"\n",
    "    Monitor CPU and RAM usage until stop_event is set.\n",
    "\n",
    "    interval: float\n",
    "      Polling time in seconds.\n",
    "    \"\"\"\n",
    "    import psutil\n",
    "    import time\n",
    "    \n",
    "    if hw_type == 'gpu':\n",
    "        import pynvml\n",
    "        \n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0) # Get device handle for GPU_0\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        cpu_util = psutil.cpu_percent(interval=interval)  # Measures over 1 second\n",
    "        ram_util = psutil.virtual_memory().used/(1024**3)\n",
    "\n",
    "        sys_util = {'timestamp': time.perf_counter(), 'cpu_util': cpu_util, 'ram_gb': ram_util}\n",
    "\n",
    "        if hw_type == 'gpu':\n",
    "            gpu_utilization = pynvml.nvmlDeviceGetUtilizationRates(handle).gpu\n",
    "            gpu_mem_used_gb = pynvml.nvmlDeviceGetMemoryInfo(handle).used/(1024**3)\n",
    "            gpu_util = {'gpu_util': gpu_utilization, 'vram_gb': gpu_mem_used_gb}\n",
    "\n",
    "            # Append GPU telemetry to system telemetry\n",
    "            sys_util = sys_util | gpu_util\n",
    "\n",
    "        # print(sys_util)\n",
    "        \n",
    "        # Store system logs\n",
    "        log.append(sys_util)\n",
    "    \n",
    "    if hw_type == 'gpu':\n",
    "        pynvml.nvmlShutdown()\n",
    "    \n",
    "    return(log)\n",
    "\n",
    "def summarize_telemetry(resource_log, hw_type):\n",
    "    \"\"\"\n",
    "    Summarize telemetry data.\n",
    "\n",
    "    resource_log: list of dict\n",
    "      Resource monitoring logs stored as a list of dictionary.\n",
    "    stage_prefix: str\n",
    "      Prefix to add to output dictionary. Choose something like 'idx_build', 'vec_search'.\n",
    "    hw_type: str\n",
    "      Hardware used. Select 'cpu' or 'gpu'.\n",
    "    \"\"\"\n",
    "\n",
    "    results_df = pd.DataFrame(resource_log)\n",
    "    sys_results = {\n",
    "                   'avg_cpu_util': results_df['cpu_util'].mean(), \n",
    "                   'max_cpu_util': results_df['cpu_util'].max(),\n",
    "                   'max_ram_gb': results_df['ram_gb'].max()\n",
    "                  }\n",
    "\n",
    "    if hw_type == 'gpu':\n",
    "        gpu_results = {'avg_gpu_util': results_df['gpu_util'].mean(), \n",
    "                   'max_gpu_util': results_df['gpu_util'].max(),\n",
    "                   'max_vram_gb': results_df['vram_gb'].max()\n",
    "                  }\n",
    "        sys_results = sys_results | gpu_results\n",
    "\n",
    "    return(sys_results)\n",
    "\n",
    "def get_telemetry(func):\n",
    "    \"\"\"Aquire CPU and GPU metrics during function calls.\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        resource_log = []\n",
    "        stop_event = threading.Event()\n",
    "        monitor_thread = threading.Thread(target=monitor_resources, \n",
    "                                                args=(stop_event, resource_log, hw_type))\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        # Start monitoring resources\n",
    "        monitor_thread.start()\n",
    "    \n",
    "        # Run function\n",
    "        result = func(*args, **kwargs)\n",
    "    \n",
    "        # Signal the monitor to stop and wait for it to finish\n",
    "        stop_event.set()\n",
    "        elapsed_time = time.perf_counter() - start_time\n",
    "        monitor_thread.join()\n",
    "    \n",
    "        # Process telemetry for index build stage\n",
    "        telemetry = summarize_telemetry(resource_log, hw_type)\n",
    "        telemetry['duration_sec'] = elapsed_time\n",
    "        return (telemetry, result)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885f049c-a02b-4b7b-bdb6-1656c6b39b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (7999994, 1024) \n",
      "\n",
      "{'load_data_avg_cpu_util': 1.5333333333333332, 'load_data_max_cpu_util': 1.6, 'load_data_max_ram_gb': 78.31558227539062, 'load_data_avg_gpu_util': 0.0, 'load_data_max_gpu_util': 0, 'load_data_max_vram_gb': 62.1982421875, 'load_data_duration_sec': 8.203247316996567}\n"
     ]
    }
   ],
   "source": [
    "@get_telemetry\n",
    "def load_bin(base_path, dtype):\n",
    "    \"\"\"\n",
    "    Load embedding vectors from a binary file written by save_bin.\n",
    "\n",
    "    Parameters:\n",
    "    - base_path: Path to file (e.g. \"/output/base.u8bin\")\n",
    "    - dtype: numpy dtype used when saving (e.g. np.float32, np.uint8, etc.)\n",
    "\n",
    "    Returns:\n",
    "    - embeddings: numpy array of shape (num_vectors, num_dimensions)\n",
    "    \"\"\"\n",
    "    with open(base_path, 'rb') as f:\n",
    "        # Read header: 2 unsigned int32, little-endian\n",
    "        header = f.read(8)\n",
    "        num_vectors, num_dimensions = struct.unpack('<II', header)\n",
    "\n",
    "        # Read remaining data as flat array\n",
    "        embeddings = np.fromfile(f, dtype=dtype, count=num_vectors * num_dimensions)\n",
    "\n",
    "    return embeddings.reshape((num_vectors, num_dimensions))\n",
    "\n",
    "@get_telemetry\n",
    "def scaler_fit_transform(X):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    return(X)\n",
    "    \n",
    "# Read cuvs-bench packed data\n",
    "base_path = f'./datasets/{DATASET_NAME}/base.fbin'\n",
    "\n",
    "if hw_type == 'cpu':\n",
    "    import faiss\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    algorithm = 'faiss-cpu_kmeans'\n",
    "    telem, X = load_bin(base_path, 'float32')\n",
    "elif hw_type == 'gpu':\n",
    "    import cuml\n",
    "    import cupy as cp\n",
    "    from cuml.preprocessing import StandardScaler\n",
    "    from cuml.model_selection import train_test_split\n",
    "    import cuvs.cluster.kmeans as cuvs_kmeans\n",
    "    from cuvs.cluster.kmeans import cluster_cost\n",
    "\n",
    "    algorithm = 'cuvs_kmeans'\n",
    "    telem, X_npy = load_bin(base_path, 'float32')\n",
    "    X = cp.array(X_npy)\n",
    "else:\n",
    "    raise ValueError(f\"hw_type '{hw_type}' unknown. Use hw_type of 'cpu' or 'gpu'.\")\n",
    "\n",
    "telem_load_data = add_prefix(telem, 'load_data_')\n",
    "print(f'Data shape: {X.shape} \\n')\n",
    "print(telem_load_data)\n",
    "\n",
    "# Get dataset metadata\n",
    "n_rows = len(X)\n",
    "dim = X.shape[1]\n",
    "X_dtype = str(X[0].dtype)\n",
    "\n",
    "# # Apply standard scaler\n",
    "# telem, X = scaler_fit_transform(X)\n",
    "# telem_standard_scaler = add_prefix(telem, 'standard_scaler_')\n",
    "\n",
    "# print(telem_standard_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888dfa61-5601-4ede-b880-b82f43552eab",
   "metadata": {},
   "outputs": [
    {
     "ename": "CuvsException",
     "evalue": "parallel_for failed: cudaErrorIllegalAddress: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCuvsException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m telem_store = []\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_clusters \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m10\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m1000\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     telem, kmeans_model = \u001b[43mtrain_kmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhw_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_delay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     telem[\u001b[33m'\u001b[39m\u001b[33mduration_sec\u001b[39m\u001b[33m'\u001b[39m] = telem[\u001b[33m'\u001b[39m\u001b[33mduration_sec\u001b[39m\u001b[33m'\u001b[39m] - time_delay\n\u001b[32m     67\u001b[39m     telem_kmeans_train = add_prefix(telem, \u001b[33m'\u001b[39m\u001b[33mkmeans_train_\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mget_telemetry.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m monitor_thread.start()\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Run function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Signal the monitor to stop and wait for it to finish\u001b[39;00m\n\u001b[32m     92\u001b[39m stop_event.set()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtrain_kmeans\u001b[39m\u001b[34m(X, n_clusters, hw_type, time_delay)\u001b[39m\n\u001b[32m     27\u001b[39m     cuvs_kmeans_params = cuvs_kmeans.KMeansParams(n_clusters=n_clusters, \n\u001b[32m     28\u001b[39m                                                   max_iter=\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[32m     29\u001b[39m                                                   **cuvs_kmeans_hierarchical_params\n\u001b[32m     30\u001b[39m                                                  )\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Train cuVS kmeans model:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     centroids, inertia, n_iter = \u001b[43mcuvs_kmeans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuvs_kmeans_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     model = {\u001b[33m'\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m'\u001b[39m: cuvs_kmeans_params, \u001b[33m'\u001b[39m\u001b[33mcentroids\u001b[39m\u001b[33m'\u001b[39m: centroids, \n\u001b[32m     35\u001b[39m              \u001b[33m'\u001b[39m\u001b[33minertia\u001b[39m\u001b[33m'\u001b[39m: inertia, \u001b[33m'\u001b[39m\u001b[33mn_iter\u001b[39m\u001b[33m'\u001b[39m: n_iter}\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cuvs/common/resources.pyx:110\u001b[39m, in \u001b[36mcuvs.common.resources.auto_sync_resources.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pylibraft/common/outputs.py:83\u001b[39m, in \u001b[36mauto_convert_output.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     ret_value = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret_value, pylibraft.common.device_ndarray):\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_cai_type(ret_value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cuvs/cluster/kmeans/kmeans.pyx:240\u001b[39m, in \u001b[36mcuvs.cluster.kmeans.kmeans.fit\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cuvs/cluster/kmeans/kmeans.pyx:241\u001b[39m, in \u001b[36mcuvs.cluster.kmeans.kmeans.fit\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/cuvs/common/exceptions.pyx:37\u001b[39m, in \u001b[36mcuvs.common.exceptions.check_cuvs\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCuvsException\u001b[39m: parallel_for failed: cudaErrorIllegalAddress: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "@get_telemetry\n",
    "def train_kmeans(X, n_clusters, hw_type, time_delay):\n",
    "    \"\"\"\n",
    "    Train KMeans model.\n",
    "    \"\"\"\n",
    "    time.sleep(time_delay)\n",
    "    if hw_type == 'cpu':\n",
    "        # https://github.com/facebookresearch/faiss/wiki/Faiss-building-blocks:-clustering,-PCA,-quantization\n",
    "        ncentroids = n_clusters # Number of centroids\n",
    "        niter = max_iter\n",
    "        verbose = True\n",
    "        d = X.shape[1] # Number of dimensions\n",
    "        faiss_kmeans = faiss.Kmeans(d, ncentroids, niter=niter, verbose=verbose, gpu=False)\n",
    "        \n",
    "        # Train FAISS-CPU kmeans model:\n",
    "        faiss_kmeans.train(X)\n",
    "        model = faiss_kmeans\n",
    "    elif hw_type == 'gpu':\n",
    "        # https://docs.rapids.ai/api/cuvs/nightly/python_api/cluster_kmeans/\n",
    "        # Balanced k_means by setting hierarchical=True\n",
    "        cuvs_kmeans_hierarchical = False\n",
    "\n",
    "        if cuvs_kmeans_hierarchical:\n",
    "            cuvs_kmeans_hierarchical_params = {'hierarchical': True, 'hierarchical_n_iters': max_iter}\n",
    "        else:\n",
    "            cuvs_kmeans_hierarchical_params = {}\n",
    "        cuvs_kmeans_params = cuvs_kmeans.KMeansParams(n_clusters=n_clusters, \n",
    "                                                      max_iter=None, \n",
    "                                                      **cuvs_kmeans_hierarchical_params\n",
    "                                                     )\n",
    "        \n",
    "        # Train cuVS kmeans model:\n",
    "        centroids, inertia, n_iter = cuvs_kmeans.fit(cuvs_kmeans_params, X)\n",
    "        model = {'params': cuvs_kmeans_params, 'centroids': centroids, \n",
    "                 'inertia': inertia, 'n_iter': n_iter}\n",
    "    return(model)\n",
    "\n",
    "@get_telemetry\n",
    "def predict_kmeans(model, X, hw_type, time_delay):\n",
    "    \"\"\"\n",
    "    Apply KMeans model to assign cluster labels.\n",
    "    \"\"\"\n",
    "    time.sleep(time_delay)\n",
    "    if hw_type == 'cpu':\n",
    "        D, labels = model.index.search(X, 1)\n",
    "        # D contains the squared L2 distances.\n",
    "        \n",
    "        # Flatten labels since we're only using first cluster assignments.\n",
    "        labels =  labels.flatten()\n",
    "        inertia = np.sum(D)\n",
    "    elif hw_type == 'gpu':\n",
    "        labels, inertia = cuvs_kmeans.predict(model['params'], X, model['centroids'])\n",
    "\n",
    "        # inertia: sum of squared distances of samples to their closest cluster center\n",
    "\n",
    "    results = {'labels': labels, 'inertia': inertia}\n",
    "    return(results)\n",
    "\n",
    "# Issue when function runs faster than polling rate (0.25s). \n",
    "# Need to slow function execution by adding an internal delay and reversing it. \n",
    "time_delay = 0.25\n",
    "\n",
    "telem_store = []\n",
    "for n_clusters in [10, 100, 1000]:\n",
    "    telem, kmeans_model = train_kmeans(X, n_clusters, hw_type, time_delay)\n",
    "    telem['duration_sec'] = telem['duration_sec'] - time_delay\n",
    "    telem_kmeans_train = add_prefix(telem, 'kmeans_train_')\n",
    "    \n",
    "    telem, kmeans_result = predict_kmeans(kmeans_model, X, hw_type, time_delay)\n",
    "    telem['duration_sec'] = telem['duration_sec'] - time_delay\n",
    "    telem_kmeans_predict = add_prefix(telem, 'kmeans_predict_')\n",
    "    \n",
    "    # Get cluster labels\n",
    "    labels = kmeans_result['labels']\n",
    "\n",
    "    telem_stages = telem_load_data | telem_kmeans_train | telem_kmeans_predict #| telem_silhouette_score\n",
    "\n",
    "    # telem_stages = telem_load_data | telem_standard_scaler | telem_kmeans_train | telem_kmeans_predict #| telem_silhouette_score\n",
    "    metadata = {\n",
    "        'dataset': DATASET_NAME,\n",
    "        'n_rows': n_rows,\n",
    "        'dimension': dim,\n",
    "        'dtype': X_dtype,\n",
    "        'hw_type': hw_type,\n",
    "        'algorithm': algorithm, \n",
    "        'num_clusters': n_clusters,\n",
    "        'inertia': kmeans_result['inertia']\n",
    "    }\n",
    "    \n",
    "    telem_store.append(metadata | telem_stages)\n",
    "\n",
    "# Write results to disk\n",
    "telem_store_df = pd.DataFrame(telem_store)\n",
    "telem_store_df.to_csv(f'./results/{hw_type}_{DATASET_NAME}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf9b4b-fcdc-4ce4-bf4a-6ab69bbe1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuvs.cluster.kmeans import cluster_cost\n",
    "\n",
    "inertia = cluster_cost(X, kmeans_model['centroids'])\n",
    "inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bcec4-96a0-42d2-8faf-49b1e67d44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c72510-d29e-4163-acca-155e2de9ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all csv files in directory and merge them\n",
    "results_csv = glob.glob(\"./results/*.csv\")\n",
    "results_csv.sort()\n",
    "\n",
    "merged_results = pd.concat([pd.read_csv(fn) for fn in results_csv]).reset_index(drop=True)\n",
    "merged_results.to_csv('merged_kmeans_results.csv', float_format='%.3f', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d98ccbb-29a5-43f0-8bff-60c5cd60dacb",
   "metadata": {},
   "source": [
    "# Stratified sampling using cluster labels. This reduces the amount of data\n",
    "# used in estimating the silhouette_score.\n",
    "print(f'Estimated samples for silhouette score computation: {int(silhouette_score_sample_fraction*len(X))}')\n",
    "\n",
    "# Samples to use for computing silhouette score:\n",
    "silhouette_score_sample_fraction = 0.1\n",
    "\n",
    "_, X_test, _, y_test = train_test_split(\n",
    "    X, labels, test_size=silhouette_score_sample_fraction, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74580b8d-888f-45c3-88b7-05d145a9808c",
   "metadata": {},
   "source": [
    "# Free some memory\n",
    "X_test = X_test.copy()\n",
    "del X"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c76b41ec-73a9-4aa4-b607-6689d35c04cd",
   "metadata": {},
   "source": [
    "@get_telemetry\n",
    "def compute_silhouette_score(X, y):\n",
    "    import cuml\n",
    "\n",
    "    time.sleep(0.25)\n",
    "    \n",
    "    silhouette_score = cuml.metrics.cluster.silhouette_score(X, y)\n",
    "    return(silhouette_score)\n",
    "\n",
    "# silhouette_score = compute_silhouette_score(X_test, y_test)\n",
    "telem, silhouette_score = compute_silhouette_score(X_test, y_test)\n",
    "telem_silhouette_score = add_prefix(telem, 'silhouette_score_')\n",
    "\n",
    "# # Compute silhouette_score on GPU\n",
    "# start_time = time.perf_counter()\n",
    "# silhouette_score = cuml.metrics.cluster.silhouette_score(X_test, y_test)\n",
    "# silhouette_score_time = time.perf_counter() - start_time\n",
    "\n",
    "# Print results\n",
    "print(f'Algorithm: {algorithm}')\n",
    "# print(f'StardardScaler fit time: {stardard_scaler_fit_time:0.2f} s')\n",
    "# print(f'StardardScaler transform time: {stardard_scaler_transform_time:0.2f} s')\n",
    "# print(f'Kmeans training time: {kmeans_train_time:0.2f} s')\n",
    "# print(f'Kmeans prediction time: {kmeans_predict_time:0.2f} s')\n",
    "print(f'Silhouette score: {silhouette_score:0.4f}')\n",
    "\n",
    "# Takes 14GB VRAM for 1M samples to compute silhouette_score. Vector and model takes 4.4GB.\n",
    "# Set chunksize < 40000 to reduce mem usage.\n",
    "# 1 <= chunksize <= n_samples to tile the pairwise distance matrix computations, \n",
    "# so as to reduce the quadratic memory usage of having the entire pairwise distance \n",
    "# matrix in GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429c649-04b2-41d6-8b18-ec7b4f0bea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP projections\n",
    "from cuml.manifold.umap import UMAP\n",
    " \n",
    "# Running default UMAP. Runs with NN Descent if data has more than 50K points\n",
    "umap = UMAP(n_neighbors=16)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "emb  = umap.fit_transform(X_test)\n",
    "umap_fit_transform_time = time.perf_counter() - start_time\n",
    "\n",
    "print(f'UMAP fit + transform time: {umap_fit_transform_time:0.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04184311-8551-4198-bc9b-50e06b63987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP projection with cluster colorized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
